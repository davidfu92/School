{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 5: Build a seq2seq model for machine translation.\n",
    "\n",
    "### Name: [David Fu]\n",
    "\n",
    "### Task: Translate English to [Estonian]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read and run my code.\n",
    "2. Complete the code in Section 1.1 and Section 4.2.\n",
    "\n",
    "    * Translation **English** to **German** is not acceptable!!! Try another pair of languages.\n",
    "    \n",
    "3. **Make improvements.** Directly modify the code in Section 3. Do at least one of the two. By doing both correctly, you will get up to 1 bonus score to the total.\n",
    "\n",
    "    * Bi-LSTM instead of LSTM.\n",
    "        \n",
    "    * Attention. (You are allowed to use existing code.)\n",
    "    \n",
    "4. Evaluate the translation using the BLEU score. \n",
    "\n",
    "    * Optional. Up to 1 bonus scores to the total.\n",
    "    \n",
    "5. Convert the notebook to .HTML file. \n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "\n",
    "6. Put the .HTML file in your Google Drive, Dropbox, or Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "7. Submit the link to the HTML file to Canvas.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint: \n",
    "\n",
    "To implement ```Bi-LSTM```, you will need the following code to build the encoder. Do NOT use Bi-LSTM for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, LSTM\n",
    "\n",
    "# encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "#                                   dropout=0.5, name='encoder_lstm'))\n",
    "# _, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "# state_h = Concatenate()([forward_h, backward_h])\n",
    "# state_c = Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "1. Download data (e.g., \"est-eng.zip\") from http://www.manythings.org/anki/\n",
    "2. Unzip the .ZIP file.\n",
    "3. Put the .TXT file (e.g., \"deu.txt\") in the directory \"./Data/\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load and clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "import numpy\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return numpy.array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the following blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., filename = 'Data/deu.txt'\n",
    "filename = 'est-eng/est.txt'\n",
    "\n",
    "# e.g., n_train = 20000\n",
    "n_train = 2187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "doc = load_doc(filename)\n",
    "\n",
    "# split into Language1-Language2 pairs\n",
    "pairs = to_pairs(doc)\n",
    "\n",
    "# clean sentences\n",
    "clean_pairs = clean_data(pairs)[0:n_train, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i wish i were by your side] => [ma sooviksin et ma oleksin su korval]\n",
      "[i wish i were by your side] => [ma sooviksin su korval olla]\n",
      "[id like a map of the city] => [ma sooviksin selle linna kaarti]\n",
      "[im not afraid of anything] => [ma ei karda midagi]\n",
      "[if i were rich id buy it] => [kui oleksin rikas siis ostaksin selle]\n",
      "[is that all right with you] => [kas see koik sobib sulle]\n",
      "[is your uncle still abroad] => [kas su onu on ikka veel valismaal]\n",
      "[life is hard for everybody] => [koigi elu on raske]\n",
      "[many people like to travel] => [paljudele inimestele meeldib reisida]\n",
      "[no one else has complained] => [keegi teine pole kurtnud]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1300, 1310):\n",
    "    print('[' + clean_pairs[i, 0] + '] => [' + clean_pairs[i, 1] + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (2187,)\n",
      "Length of target_texts: (2187,)\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of input  sentences: 96\n",
      "max length of target sentences: 92\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, you have two lists of sentences: input_texts and target_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text processing\n",
    "\n",
    "### 2.1. Convert texts to sequences\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (2187, 96)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (2187, 92)\n",
      "shape of target_token_index: 27\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# encode and pad sequences\n",
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, \n",
    "                                                      input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, \n",
    "                                                       target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 28\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, the input language and target language texts are converted to 2 matrices. \n",
    "\n",
    "- Their number of rows are both n_train.\n",
    "- Their number of columns are respective max_encoder_seq_length and max_decoder_seq_length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings print a sentence and its representation as a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tkui sugav\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 14,  9,  4,  1,  5,  9, 19,  2, 17, 13,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_seq[100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One-hot encode\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding.\n",
    "- It is represented by a $n\\times t \\times v$ tensor ($t$ is the number of unique chars) after the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2187, 96, 28)\n",
      "(2187, 92, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# one hot encode target sequence\n",
    "def onehot_encode(sequences, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = numpy.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data\n",
    "\n",
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the networks (for training)\n",
    "\n",
    "- Build encoder, decoder, and connect the two modules to get \"model\". \n",
    "\n",
    "- Fit the model on the bilingual data to train the parameters in the encoder and decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Encoder network\n",
    "\n",
    "- Input:  one-hot encode of the input language\n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states   $h_1, \\cdots , h_t$) are always discarded\n",
    "    \n",
    "    -- the final hidden state  $h_t$\n",
    "    \n",
    "    -- the final conveyor belt $c_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "# # set the LSTM layer\n",
    "# encoder_lstm = LSTM(latent_dim, return_state=True, \n",
    "#                     dropout=0.5, name='encoder_lstm')\n",
    "\n",
    "# _, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# # set the BiDirectional LSTM layer\n",
    "encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "                                  dropout=0.5, name='encoder_lstm'))\n",
    "\n",
    "encoder_lstm_output, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "encoder_state_h = Concatenate()([forward_h, backward_h])\n",
    "encoder_state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[encoder_state_h, encoder_state_c],\n",
    "                      name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary and save the encoder network structure to \"./encoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 512), (None, 583680      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "==================================================================================================\n",
      "Total params: 583,680\n",
      "Trainable params: 583,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=encoder_model, show_shapes=False,\n",
    "    to_file='encoder.pdf'\n",
    ")\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Decoder network\n",
    "\n",
    "- Inputs:  \n",
    "\n",
    "    -- one-hot encode of the target language\n",
    "    \n",
    "    -- The initial hidden state $h_t$ \n",
    "    \n",
    "    -- The initial conveyor belt $c_t$ \n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states) $h_1, \\cdots , h_t$\n",
    "\n",
    "    -- the final hidden state  $h_t$ (discarded in the training and used in the prediction)\n",
    "    \n",
    "    -- the final conveyor belt $c_t$ (discarded in the training and used in the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# inputs of the decoder network\n",
    "decoder_input_h = Input(shape=(latent_dim*2,), name='decoder_input_h')\n",
    "decoder_input_c = Input(shape=(latent_dim*2,), name='decoder_input_c')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, \n",
    "                    return_state=True, dropout=0.5, name='decoder_lstm')\n",
    "decoder_lstm_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_input_x, \n",
    "                                                      initial_state=[decoder_input_h, decoder_input_c])\n",
    "\n",
    "# set the dense layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
    "                      outputs=[decoder_outputs, decoder_state_h, decoder_state_c],\n",
    "                      name='decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary and save the encoder network structure to \"./decoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 28)     14364       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,122,332\n",
      "Trainable params: 1,122,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "\n",
    "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=decoder_model, show_shapes=False,\n",
    "    to_file='decoder.pdf'\n",
    ")\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Connect the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 28)     14364       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,706,012\n",
      "Trainable params: 1,706,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states = encoder_model([encoder_input_x])\n",
    "decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
    "decoder_pred = decoder_dense(decoder_lstm_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name='decoder_input_h'), name='decoder_input_h', description=\"created by layer 'decoder_input_h'\")\n"
     ]
    }
   ],
   "source": [
    "print(encoder_state_h)\n",
    "print(decoder_input_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 28)     14364       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,706,012\n",
      "Trainable params: 1,706,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=model, show_shapes=False,\n",
    "    to_file='model_training.pdf'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.v2 Enhance Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attn_inputs_encoder (InputLayer [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attn_inputs_decoder (InputLayer [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (Attention)     (None, 512)          0           attn_inputs_encoder[0][0]        \n",
      "                                                                 attn_inputs_decoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           attention_layer[0][0]            \n",
      "                                                                 attn_inputs_decoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attn_dense (Dense)              (None, 1024)         1049600     concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,049,600\n",
      "Trainable params: 1,049,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"ehance_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "attn_model (Functional)         (None, 1024)         1049600     encoder[1][0]                    \n",
      "                                                                 decoder_lstm[2][1]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1536)         0           attn_model[0][0]                 \n",
      "                                                                 decoder_lstm[2][1]               \n",
      "__________________________________________________________________________________________________\n",
      "enhance_dense (Dense)           (None, 1024)         1573888     concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,315,136\n",
      "Trainable params: 4,315,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Attention\n",
    "attn_inputs_encoder = Input(shape=(512), \n",
    "                       name='attn_inputs_encoder')\n",
    "\n",
    "attn_inputs_decoder = Input(shape=(512), \n",
    "                       name='attn_inputs_decoder')\n",
    "\n",
    "attn_layer = Attention(name='attention_layer')\n",
    "attn_state_c = attn_layer([attn_inputs_encoder, attn_inputs_decoder])\n",
    "\n",
    "concat_state = Concatenate()([attn_state_c, attn_inputs_decoder])\n",
    "\n",
    "attn_dense = Dense(1024, activation='softmax', name='attn_dense')\n",
    "final_state = attn_dense(concat_state)\n",
    "attn_model = Model(inputs=[attn_inputs_encoder, attn_inputs_decoder],\n",
    "                outputs=final_state, name='attn_model')\n",
    "\n",
    "attn_model.summary()\n",
    "\n",
    "# Updated Decoder Model\n",
    "ehanced_decoder_dense = Dense(1024, activation='softmax', name='enhance_dense')\n",
    "\n",
    "# connect encoder to decoder and attention\n",
    "decoder_pred = decoder_dense(decoder_lstm_output)\n",
    "\n",
    "encoder_final_h, encoder_final_c = encoder_model([encoder_input_x])\n",
    "decoder_lstm_output, decoder_final_h, decoder_final_c = decoder_lstm(decoder_input_x, initial_state=[encoder_final_h, encoder_final_c])\n",
    "attn_final_c = attn_model((encoder_final_h, decoder_final_h))\n",
    "concat_pre = Concatenate()([attn_final_c, decoder_final_h])\n",
    "enhance_pred = ehanced_decoder_dense(concat_pre)\n",
    "\n",
    "enhance_decoder_model = Model(inputs=[encoder_input_x, decoder_input_x],\n",
    "                      outputs=enhance_pred,\n",
    "                      name='ehance_model')\n",
    "\n",
    "enhance_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 28)     14364       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,706,012\n",
      "Trainable params: 1,706,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "\n",
    "SVG(model_to_dot(enhance_decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=enhance_decoder_model, show_shapes=False,\n",
    "    to_file='attention_model.pdf'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Fit the model on the bilingual dataset\n",
    "\n",
    "- encoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_target_data: labels (left shift of decoder_input_data)\n",
    "\n",
    "- tune the hyper-parameters\n",
    "\n",
    "- stop when the validation loss stop decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_data(2187, 96, 28)\n",
      "shape of decoder_input_data(2187, 92, 28)\n",
      "shape of decoder_target_data(2187, 92, 28)\n"
     ]
    }
   ],
   "source": [
    "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
    "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
    "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 39s 321ms/step - loss: 1.3052 - val_loss: 2.7463\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 80s 729ms/step - loss: 0.7419 - val_loss: 1.1894\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 43s 391ms/step - loss: 0.6588 - val_loss: 1.0977\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 48s 435ms/step - loss: 0.6296 - val_loss: 1.0920\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 44s 400ms/step - loss: 0.6266 - val_loss: 1.0385\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 48s 440ms/step - loss: 0.5955 - val_loss: 1.0237\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 47s 425ms/step - loss: 0.5880 - val_loss: 0.9924\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 42s 381ms/step - loss: 0.5762 - val_loss: 1.0050\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 42s 380ms/step - loss: 0.5633 - val_loss: 0.9743\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 40s 367ms/step - loss: 0.5534 - val_loss: 0.9723\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 40s 364ms/step - loss: 0.5464 - val_loss: 0.9215\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 39s 357ms/step - loss: 0.5347 - val_loss: 0.9191\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 35s 321ms/step - loss: 0.5248 - val_loss: 0.8969\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 0.5316 - val_loss: 0.9074\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 50s 455ms/step - loss: 0.5268 - val_loss: 0.9113\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 45s 410ms/step - loss: 0.5095 - val_loss: 0.8970\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 53s 481ms/step - loss: 0.5071 - val_loss: 0.8709\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 58s 523ms/step - loss: 0.4968 - val_loss: 0.8557\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 46s 416ms/step - loss: 0.4947 - val_loss: 0.8687\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 48s 437ms/step - loss: 0.4873 - val_loss: 0.8667\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 48s 435ms/step - loss: 0.4926 - val_loss: 0.8712\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 56s 506ms/step - loss: 0.4824 - val_loss: 0.8709\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 48s 435ms/step - loss: 0.4718 - val_loss: 0.8563\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 52s 473ms/step - loss: 0.4736 - val_loss: 0.8378\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 52s 474ms/step - loss: 0.4738 - val_loss: 0.8364\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 52s 472ms/step - loss: 0.4561 - val_loss: 0.8460\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 50s 458ms/step - loss: 0.4557 - val_loss: 0.8242\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 50s 452ms/step - loss: 0.4430 - val_loss: 0.8470\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 58s 529ms/step - loss: 0.4514 - val_loss: 0.8445\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 55s 496ms/step - loss: 0.4307 - val_loss: 0.8440\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 59s 534ms/step - loss: 0.4311 - val_loss: 0.8455\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 63s 576ms/step - loss: 0.4239 - val_loss: 0.8583\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 57s 520ms/step - loss: 0.4200 - val_loss: 0.8495\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 59s 532ms/step - loss: 0.4122 - val_loss: 0.8565\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 51s 463ms/step - loss: 0.4145 - val_loss: 0.8572\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 56s 511ms/step - loss: 0.4188 - val_loss: 0.8614\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 53s 477ms/step - loss: 0.4034 - val_loss: 0.8620\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 47s 431ms/step - loss: 0.4005 - val_loss: 0.8746\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 51s 465ms/step - loss: 0.4043 - val_loss: 0.8724\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 52s 473ms/step - loss: 0.3916 - val_loss: 0.8666\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 49s 442ms/step - loss: 0.3842 - val_loss: 0.8766\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 54s 494ms/step - loss: 0.3781 - val_loss: 0.8818\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 51s 463ms/step - loss: 0.3826 - val_loss: 0.8939\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 0.3691 - val_loss: 0.9014\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 52s 472ms/step - loss: 0.3681 - val_loss: 0.8764\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 51s 466ms/step - loss: 0.3613 - val_loss: 0.9054\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 49s 449ms/step - loss: 0.3628 - val_loss: 0.8948\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 50s 457ms/step - loss: 0.3606 - val_loss: 0.8896\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 54s 495ms/step - loss: 0.3522 - val_loss: 0.9095\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 49s 448ms/step - loss: 0.3474 - val_loss: 0.9129\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 49s 446ms/step - loss: 0.3372 - val_loss: 0.9105\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 52s 471ms/step - loss: 0.3426 - val_loss: 0.9041\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 51s 466ms/step - loss: 0.3350 - val_loss: 0.9386\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 51s 465ms/step - loss: 0.3262 - val_loss: 0.9283\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 45s 407ms/step - loss: 0.3305 - val_loss: 0.9271\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 53s 483ms/step - loss: 0.3219 - val_loss: 0.9646\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 45s 412ms/step - loss: 0.3220 - val_loss: 0.9545\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 52s 469ms/step - loss: 0.3090 - val_loss: 0.9597\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 51s 461ms/step - loss: 0.3084 - val_loss: 0.9471\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 51s 461ms/step - loss: 0.3099 - val_loss: 0.9593\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 54s 488ms/step - loss: 0.3027 - val_loss: 0.9632\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 49s 442ms/step - loss: 0.3006 - val_loss: 0.9744\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 52s 476ms/step - loss: 0.2976 - val_loss: 0.9749\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 53s 483ms/step - loss: 0.2957 - val_loss: 1.0019\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 50s 452ms/step - loss: 0.2891 - val_loss: 0.9865\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 54s 490ms/step - loss: 0.2867 - val_loss: 0.9994\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 51s 464ms/step - loss: 0.2785 - val_loss: 1.0241\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 51s 465ms/step - loss: 0.2892 - val_loss: 0.9976\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 50s 457ms/step - loss: 0.2782 - val_loss: 1.0111\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 51s 468ms/step - loss: 0.2754 - val_loss: 1.0471\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 46s 423ms/step - loss: 0.2671 - val_loss: 1.0268\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 49s 446ms/step - loss: 0.2693 - val_loss: 1.0543\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 49s 448ms/step - loss: 0.2735 - val_loss: 1.0395\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 50s 455ms/step - loss: 0.2723 - val_loss: 1.0755\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 49s 442ms/step - loss: 0.2631 - val_loss: 1.0868\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 49s 450ms/step - loss: 0.2516 - val_loss: 1.0745\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 49s 441ms/step - loss: 0.2475 - val_loss: 1.0713\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 48s 441ms/step - loss: 0.2502 - val_loss: 1.0670\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 50s 458ms/step - loss: 0.2504 - val_loss: 1.0677\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 52s 472ms/step - loss: 0.2493 - val_loss: 1.0860\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 49s 446ms/step - loss: 0.2461 - val_loss: 1.0997\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 50s 454ms/step - loss: 0.2403 - val_loss: 1.0888\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 48s 435ms/step - loss: 0.2418 - val_loss: 1.0928\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 50s 458ms/step - loss: 0.2408 - val_loss: 1.0706\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 49s 448ms/step - loss: 0.2368 - val_loss: 1.0926\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 45s 408ms/step - loss: 0.2284 - val_loss: 1.1012\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 43s 389ms/step - loss: 0.2430 - val_loss: 1.1077\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 47s 425ms/step - loss: 0.2282 - val_loss: 1.1066\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 47s 427ms/step - loss: 0.2220 - val_loss: 1.1030\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 46s 422ms/step - loss: 0.2231 - val_loss: 1.1409\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 48s 434ms/step - loss: 0.2242 - val_loss: 1.1237\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 47s 432ms/step - loss: 0.2108 - val_loss: 1.1380\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 46s 419ms/step - loss: 0.2174 - val_loss: 1.1507\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 47s 428ms/step - loss: 0.2148 - val_loss: 1.1593\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 46s 420ms/step - loss: 0.2046 - val_loss: 1.1453\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 41s 369ms/step - loss: 0.2136 - val_loss: 1.1658\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 44s 397ms/step - loss: 0.2045 - val_loss: 1.1918\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 45s 407ms/step - loss: 0.2007 - val_loss: 1.1888\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 39s 350ms/step - loss: 0.2015 - val_loss: 1.1793\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 35s 314ms/step - loss: 0.2099 - val_loss: 1.1576\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "          decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "          batch_size=16, epochs=100, validation_split=0.2)\n",
    "\n",
    "model.save('seq2seq.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance_decoder_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# enhance_decoder_model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "#           decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "#           batch_size=16, epochs=100, validation_split=0.2)\n",
    "\n",
    "# enhance_decoder_model.save('seq2seqattention.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions\n",
    "\n",
    "\n",
    "### 4.1. Translate English to Estonian\n",
    "\n",
    "1. Encoder read a sentence (source language) and output its final states, $h_t$ and $c_t$.\n",
    "2. Take the [star] sign \"\\t\" and the final state $h_t$ and $c_t$ as input and run the decoder.\n",
    "3. Get the new states and predicted probability distribution.\n",
    "4. sample a char from the predicted probability distribution\n",
    "5. take the sampled char and the new states as input and repeat the process (stop if reach the [stop] sign \"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # this line of code is greedy selection\n",
    "        # try to use multinomial sampling instead (with temperature)\n",
    "        sampled_token_index = numpy.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "English:        my sunglasses were stolen at the beach yesterday\n",
      "Estonian (true):  mu paikeseprillid varastati eile rannas ara\n",
      "Estonian (pred):  mu noorem vend vaatab televiisorit\n",
      "-\n",
      "English:        the period is missing at the end of the sentence\n",
      "Estonian (true):  lause lopus puudub punkt\n",
      "Estonian (pred):  tonaut kari maadad in taisi\n",
      "-\n",
      "English:        this flower is the most beautiful of all flowers\n",
      "Estonian (true):  see lill on kauneim koigist lilledest\n",
      "Estonian (pred):  see sird tahtud on pagem kui mitte midagi\n",
      "-\n",
      "English:        tom grabbed marys right hand with his left hand\n",
      "Estonian (true):  tom haaras oma vasaku kaega mary parema\n",
      "Estonian (pred):  tom utles et keegi teine ei olnud naljane\n",
      "-\n",
      "English:        tom isnt sure what he wants to do with his life\n",
      "Estonian (true):  tom pole kindel mida ta oma eluga peale tahab hakata\n",
      "Estonian (pred):  tom ei raaki kedus prantsuse keele opetaja\n",
      "-\n",
      "English:        what language do they speak in the united states\n",
      "Estonian (true):  mis keelt ameerika uhendriikides raagitakse\n",
      "Estonian (pred):  millest see temmel ehillallili loogellele\n",
      "-\n",
      "English:        which do you like better white wine or red wine\n",
      "Estonian (true):  kumba sa eelistad kas valget voi punast veini\n",
      "Estonian (pred):  kellelt ooe tehdlalee ila peilameel\n",
      "-\n",
      "English:        why are you sorry for something you havent done\n",
      "Estonian (true):  miks sa palud vabandust millegi parast mida sa teinud ei ole\n",
      "Estonian (pred):  miks sa tend tainis on minu oma\n",
      "-\n",
      "English:        how long does it take to get to the train station\n",
      "Estonian (true):  kui kaua votab aega rongijaama joudmine\n",
      "Estonian (pred):  kui tihti bostonis sajab\n",
      "-\n",
      "English:        i cant remember the last time i saw tom so happy\n",
      "Estonian (true):  ma ei maleta millal ma tomi viimati nii onnelikuna nagin\n",
      "Estonian (pred):  ma ei saa seda tomale st ta tulebab malle\n",
      "-\n",
      "English:        this was too difficult a problem for her to solve\n",
      "Estonian (true):  see oli liiga raske probleem talle lahendada\n",
      "Estonian (pred):  see ei olnud hea kogelas la valmemarakame\n",
      "-\n",
      "English:        you seem to have lost sight of original objective\n",
      "Estonian (true):  tundub et sa oled algse eesmargi unustanud\n",
      "Estonian (pred):  su pead regle modagi see mida mis ta pesisin\n",
      "-\n",
      "English:        remain in your seats with your seat belts fastened\n",
      "Estonian (true):  palun jaage oma kohtadele turvarihmad kinni\n",
      "Estonian (pred):  ma onnust sin ta kuha anakiik liske rusku\n",
      "-\n",
      "English:        the judge sentenced him to one years imprisonment\n",
      "Estonian (true):  kohtunik moistis ta aastaks ajaks vangi\n",
      "Estonian (pred):  torvar on ikka veel valju oppida\n",
      "-\n",
      "English:        he is such a bad person that everybody dislikes him\n",
      "Estonian (true):  ta on niivord halb inimene et ta ei meeldi kellelegi\n",
      "Estonian (pred):  ta on minust kaks tolli piksm\n",
      "-\n",
      "English:        he was wrong in thinking that shed come to see him\n",
      "Estonian (true):  ta eksis arvates et ta tuli teda vaatama\n",
      "Estonian (pred):  ta kardab pulanud vaika\n",
      "-\n",
      "English:        i dont have a lot of time can you take care of it\n",
      "Estonian (true):  mul pole palju aega kas sa saad selle korda ajada\n",
      "Estonian (pred):  mul ei olnud nagunid kiinel koia laskulasi korrus\n",
      "-\n",
      "English:        i wish you were wrong but i know that youre right\n",
      "Estonian (true):  soovin et sa eksiks aga tean et sul on oigus\n",
      "Estonian (pred):  ma soovin et sa saad melle koos olt manu tada\n",
      "-\n",
      "English:        id explain it to you but your brain would explode\n",
      "Estonian (true):  ma seletaksin seda sulle aga su aju plahvataks\n",
      "Estonian (pred):  ma olen sulle jargmike keeva rakkama\n",
      "-\n",
      "English:        it is clear that no one has anything new to suggest\n",
      "Estonian (true):  on selge et kellelgi ei ole mingeid uusi ettepanekuid\n",
      "Estonian (pred):  see on kiiremata aeselaselt millemarakleme\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(2100, 2120):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('English:       ', input_texts[seq_index])\n",
    "    print('Estonian (true): ', target_texts[seq_index][1:-1])\n",
    "    print('Estonian (pred): ', decoded_sentence[0:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Translate an English sentence to the target language\n",
    "\n",
    "1. Tokenization\n",
    "2. One-hot encode\n",
    "3. Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "source sentence is: i love you\n",
      "translated sentence is: ma laan sida\n",
      "-\n",
      "source sentence is: i solve the problem\n",
      "translated sentence is: ma opin selle ala aala\n"
     ]
    }
   ],
   "source": [
    "input_sentences = numpy.array(['i love you','i solve the problem'])\n",
    "input_sequences, input_index = text2sequences(max_encoder_seq_length, input_sentences)\n",
    "encoded_input_x = onehot_encode(input_sequences, max_encoder_seq_length, num_encoder_tokens)\n",
    "\n",
    "for seq_index in range(0, len(input_sentences)):\n",
    "    input_seq = encoded_input_x[seq_index: seq_index + 1]\n",
    "    translated_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('source sentence is: ' + input_sentences[seq_index])\n",
    "    print('translated sentence is: ' + translated_sentence[0:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the translation using BLEU score\n",
    "\n",
    "Reference: \n",
    "- https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "- https://en.wikipedia.org/wiki/BLEU\n",
    "\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "- Randomly partition the dataset to training, validation, and test. \n",
    "\n",
    "- Evaluate the BLEU score using the test set. Report the average.\n",
    "\n",
    "- A reasonable BLEU score should be 0.1 ~ 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_remain, y_train, y_remain = train_test_split(encoder_input_data, target_texts, test_size=0.20, random_state=11)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_remain, y_remain, test_size=0.1, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of BLEU score for LSTM:  0.36975452840460477\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "bleu_score = -1\n",
    "\n",
    "for seq_index in range(1, len(x_test)-1):\n",
    "    input_seq = x_test[seq_index: seq_index + 1]\n",
    "    translated_sentence = decode_sequence(input_seq)\n",
    "    reference = translated_sentence[0:-1]\n",
    "    candidate = y_test[seq_index]\n",
    "    result = sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method7)\n",
    "    if bleu_score == -1:\n",
    "        bleu_score = result\n",
    "    else:\n",
    "        bleu_score = (bleu_score + result)/2\n",
    "        \n",
    "print(\"The mean of BLEU score for LSTM: \", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
